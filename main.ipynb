{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b75c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[재생 시간 : 2.08초]\n",
      "[FPS : 8.18]\n"
     ]
    }
   ],
   "source": [
    "## 얼굴 추적 카운팅 누적_2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import datetime\n",
    "import imutils\n",
    "import dlib\n",
    "\n",
    "from centroidtracker import CentroidTracker\n",
    "from trackableobject import TrackableObject\n",
    "from imutils.video import FPS\n",
    "\n",
    "# 중심 추적 변수\n",
    "ct = CentroidTracker(maxDisappeared=100, maxDistance=100)\n",
    "\n",
    "# 추적 객체 목록\n",
    "trackers = []\n",
    "\n",
    "# 추적 객체 ID\n",
    "trackableObjects = {}\n",
    "\n",
    "# 총 프레임 수\n",
    "totalFrames = 0 # 총 프레임 수\n",
    "\n",
    "# 총 이동 객체 수\n",
    "totalRight = 0\n",
    "totalLeft = 0\n",
    "\n",
    "# fps 정보 초기화\n",
    "fps = FPS().start()\n",
    "\n",
    "# 객체 시작점 튜플\n",
    "object_start_tuple = ()\n",
    "\n",
    "\n",
    "## 얼굴\n",
    "model = './opencv_face_detector_uint8.pb'\n",
    "config = './opencv_face_detector.pbtxt'\n",
    "\n",
    "cap = cv2.VideoCapture('./data/cctv_5_cut.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed')\n",
    "    cap.release()\n",
    "    sys.exit()\n",
    "\n",
    "face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('net load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        print('Video frame failed')\n",
    "        break\n",
    "        \n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                                swapRB = False)\n",
    "    face_net.setInput(blob)\n",
    "    out = face_net.forward()\n",
    "\n",
    "    detect = out[0, 0, :, :]\n",
    "    \n",
    "    # print(detect.shape)\n",
    "    h, w = img.shape[:2]\n",
    "    threshold = 0.4\n",
    "    \n",
    "    # RGB 변환\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 객체 bounding box 목록\n",
    "    rects = []\n",
    "    # 객체 추적 목록 초기화\n",
    "    trackers = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > threshold:\n",
    "            x1 = int(detect[i,3]*w)\n",
    "            y1 = int(detect[i,4]*h)\n",
    "            x2 = int(detect[i,5]*w)\n",
    "            y2 = int(detect[i,6]*h)\n",
    "\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "    #         text = f'Face: {confidence*100:4.2f}%'\n",
    "            text = 'No.{} Face:{}%'.format(i,round(confidence*100, 2))\n",
    "            cv2.putText(img, text, (x1, y1-3), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "\n",
    "            # bounding box 위치 계산\n",
    "            box = detect[i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # 객체 추적 정보 추출\n",
    "            tracker = dlib.correlation_tracker()\n",
    "            rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "            tracker.start_track(rgb, rect)\n",
    "\n",
    "            # 인식된 객체를 추적 목록에 추가\n",
    "            trackers.append(tracker)\n",
    "\n",
    "\n",
    "            #mosaic\n",
    "            img_mosaic = img[y1+3:y2-3, x1+3:x2-3]\n",
    "            m = img_mosaic.shape[0]\n",
    "            n = img_mosaic.shape[1]\n",
    "\n",
    "\n",
    "            img_mosaic = cv2.resize(img_mosaic, None, fx=0.1, fy=0.1, interpolation=cv2.INTER_AREA)\n",
    "            img_mosaic = cv2.resize(img_mosaic, (n, m), interpolation=cv2.INTER_AREA)\n",
    "            img[y1+3:y2-3, x1+3:x2-3] = img_mosaic\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # 추적된 객체 수 만큼 반복\n",
    "    for tracker in trackers:\n",
    "        # 추적된 객체 위치\n",
    "        tracker.update(rgb)\n",
    "        pos = tracker.get_position()\n",
    "        \n",
    "        # bounding box 좌표 추출\n",
    "        startX = int(pos.left())\n",
    "        startY = int(pos.top())\n",
    "        endX = int(pos.right())\n",
    "        endY = int(pos.bottom())\n",
    "\n",
    "        # bounding box 좌표 추가\n",
    "        rects.append((startX, startY, endX, endY))\n",
    "\n",
    "        # bounding box 출력\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "           \n",
    "            \n",
    "\n",
    "    \n",
    "    # Counting Line\n",
    "    cv2.line(img, (w // 2, 0), (w // 2, h), (0, 0, 255), 2)\n",
    "    cv2.putText(img, \"Counting Line\", ((w // 2) + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # 객체 중심 추적\n",
    "    objects = ct.update(rects)\n",
    "\n",
    "    # 추적된 객체 수 만큼 반복\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # 현재 객체 ID에 대해 추적 가능한 객체 확인\n",
    "        to = trackableObjects.get(objectID, None)\n",
    "        \n",
    "        # 추적 가능한 객체가 없는 경우\n",
    "        if to is None:\n",
    "            # 하나의 객체를 생성\n",
    "            to = TrackableObject(objectID, centroid)\n",
    "\n",
    "        # 추적 가능한 객체가 있는 경우\n",
    "        else:\n",
    "            # 이전의 중심 좌표에 대한 가로 좌표 값을 추출\n",
    "            y = [c[0] for c in to.centroids]\n",
    "\n",
    "            # 현재 중심 좌표와 이전 중심 좌표의 평균의 차이를 이용하여 방향을 계산\n",
    "            direction = centroid[0] - np.mean(y)\n",
    "\n",
    "            # 중심 좌표 추가\n",
    "            to.centroids.append(centroid)\n",
    "            \n",
    "            # 객체가 counting 되지 않았을 때\n",
    "            if not to.counted:\n",
    "                # 객체가 왼쪽에서 시작\n",
    "                if centroid[0] < (w // 2) - 20:\n",
    "                    try:\n",
    "                        if len(object_start_tuple) < objectID:\n",
    "                            object_start_tuple = object_start_tuple + (0,)\n",
    "                        elif len(object_start_tuple) == objectID:\n",
    "                            object_start_tuple = object_start_tuple + (-1,)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # 객체가 오른쪽에서 시작\n",
    "                elif centroid[0] > (w // 2) + 20:\n",
    "                    try:\n",
    "                        if len(object_start_tuple) < objectID:\n",
    "                            object_start_tuple = object_start_tuple + (0,)\n",
    "                        elif len(object_start_tuple) == objectID:\n",
    "                            object_start_tuple = object_start_tuple + (1,)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                try:\n",
    "                    # 객체가 왼쪽으로 이동\n",
    "                    if object_start_tuple[objectID] == 1 and direction < 0 and centroid[0] < w // 2:\n",
    "                        to.counted = True\n",
    "                        totalLeft += 1\n",
    "                        print(\"Left\")\n",
    "                        \n",
    "                    # 객체가 오른쪽으로 이동\n",
    "                    elif object_start_tuple[objectID] == -1 and direction > 0 and centroid[0] > w // 2:\n",
    "                        to.counted = True\n",
    "                        totalRight += 1\n",
    "                        print(\"Right\")\n",
    "                except:\n",
    "                    print(\"error\")\n",
    "                    pass\n",
    "        \n",
    "        # 추적 가능한 객체 저장\n",
    "        trackableObjects[objectID] = to\n",
    "        \n",
    "        # 객체 ID\n",
    "        text = \"ID {}\".format(objectID)\n",
    "\n",
    "        # 객체 ID 출력\n",
    "        cv2.putText(img, text, (centroid[0] - 10, centroid[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # 객체 중심 좌표 출력\n",
    "        cv2.circle(img, (centroid[0], centroid[1]), 4, (0, 255, 0), -2)\n",
    "\n",
    "    # Counting 정보\n",
    "    info = [\n",
    "            (\"Left\", totalLeft),\n",
    "            (\"Right\", totalRight),\n",
    "    ]\n",
    "\n",
    "    # Counting 정보를 반복\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        # Counting 정보\n",
    "        text = \"{} : {}\".format(k, v)\n",
    "\n",
    "        # Counting 정보 출력\n",
    "        cv2.putText(img, text, (400, h - ((i * 20) + 20)-100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('image', img)\n",
    "    \n",
    "    if cv2.waitKey(1) ==  ord('q'):\n",
    "        break\n",
    "\n",
    "    # 총 프레임 수 증가\n",
    "    totalFrames += 1\n",
    "    \n",
    "    # fps 정보 업데이트\n",
    "    fps.update()\n",
    "        \n",
    "        \n",
    "# fps 정지 및 정보 출력\n",
    "fps.stop()\n",
    "print(\"[재생 시간 : {:.2f}초]\".format(fps.elapsed()))\n",
    "print(\"[FPS : {:.2f}]\".format(fps.fps()))\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_cv",
   "language": "python",
   "name": "proj_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
